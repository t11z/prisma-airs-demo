# DAG for Prisma AIRS-enabled chat flow.

name: prisma-airs-chat
version: 0.1.0

description: |
  Chat flow that wraps model input and output with Prisma AIRS inline scans.
  User messages are scanned before they hit the model, and model responses
  are scanned again before being returned.

inputs:
  user_input:
    type: string
    description: Raw message from the end user.
  user_id:
    type: string
    description: Optional identifier to route Prisma AIRS policy decisions.
    default: ""

outputs:
  response_text:
    type: string
    description: Final assistant reply after scanning steps.
    value: ${response.output}

nodes:
  - name: user_input
    type: input
    description: Entry point for user-provided text.

  - name: airs_input_scan
    type: python
    source: ../tools/prisma_airs_scan.py
    function: scan_input
    description: Scan user input before the model using Prisma AIRS.
    inputs:
      content: ${inputs.user_input}
      user_id: ${inputs.user_id}
    # The Python function returns a dict; Prompt Flow exposes it as "output".
    # Expected keys include:
    #   - scanned_content
    #   - status
    #   - reason
    #   - result

  - name: llm_call
    type: llm
    description: LLM invocation using Prisma AIRS-sanitized content.
    inputs:
      # Use the scanned / possibly redacted content as prompt.
      prompt: ${airs_input_scan.output.scanned_content}
    # TODO: Configure connection and deployment name for the model, for example:
    # connection: your-aoai-connection
    # deployment_name: gpt-4o-mini
    # Additional prompt template and variables can also be configured here.

  - name: airs_output_scan
    type: python
    source: ../tools/prisma_airs_scan.py
    function: scan_output
    description: Scan model output before user delivery using Prisma AIRS.
    inputs:
      content: ${llm_call.output}
      user_id: ${inputs.user_id}
    # The return value mirrors the structure from scan_input (dict with
    # scanned_content, status, reason, result, etc.).

  - name: response
    type: output
    description: Final surface for delivering the assistant response.
    inputs:
      # Return the scanned (and potentially redacted) model response.
      value: ${airs_output_scan.output.scanned_content}
